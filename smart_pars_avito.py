import os, signal, atexit, re
import json, time, random
from base64 import b64decode
from io import BytesIO
from pathlib import Path
from urllib.parse import urljoin

import pandas as pd
from PIL import Image
from playwright.sync_api import (
    sync_playwright,
    Page,
    TimeoutError as PWTimeoutError,
    Error as PWError,
)

# –ù–ê–°–¢–†–û–ô–ö–ò


# –í–•–û–î–ù–û–ô –§–ê–ô–õ –° –°–°–´–õ–ö–ê–ú–ò
INPUT_FILE = Path("–†–ï–ú–û–ù–¢ –ú–°–ö –ú–û 13.11.xlsx")  # –ò–º—è Excel/CSV-—Ñ–∞–π–ª–∞ —Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è

INPUT_SHEET = None  # –ò–º—è –ª–∏—Å—Ç–∞ –≤ Excel; None = –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ –ª–∏—Å—Ç—ã
URL_COLUMN = None   # –ò–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å–æ —Å—Å—ã–ª–∫–∞–º–∏; None = –∏—Å–∫–∞—Ç—å —Å—Å—ã–ª–∫–∏ –≤–æ –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö

# –ü–ê–ü–ö–ò –ò –û–°–ù–û–í–ù–´–ï –í–´–•–û–î–ù–´–ï –§–ê–ô–õ–´
OUT_DIR = Path("avito_phones_playwright")  # –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø–∞—Ä—Å–µ—Ä–∞
OUT_DIR.mkdir(exist_ok=True)
IMG_DIR = (OUT_DIR / "phones")  # –°—é–¥–∞ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è PNG —Å –Ω–æ–º–µ—Ä–∞–º–∏ (–µ—Å–ª–∏ SAVE_DATA_URI = False  (–¢–æ —á—Ç–æ –Ω–µ –ø—Ä–æ–≤—Ä—è–ª–∏ –¥–∞–≤–Ω–æ –∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è))
IMG_DIR.mkdir(exist_ok=True)
DEBUG_DIR = OUT_DIR / "debug"  # –°—é–¥–∞ —Å–∫–ª–∞–¥—ã–≤–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –∏ html –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
DEBUG_DIR.mkdir(exist_ok=True)

OUT_JSON = (OUT_DIR / "phones_map.json")          # –û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {url: data:image... –∏–ª–∏ —Ç–µ–≥ __SKIP_*__}
PENDING_JSON = (OUT_DIR / "pending_review.json")  # –°—Å—ã–ª–∫–∏ ¬´–Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏¬ª –∏ —Å –ª–∏–º–∏—Ç–æ–º –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –Ω–∞ –±—É–¥—É—â–µ–µ)
SAVE_DATA_URI = (True)                            # True = —Å–æ—Ö—Ä–∞–Ω—è–µ–º data:image –≤ JSON; False = —Å–æ—Ö—Ä–∞–Ω—è–µ–º PNG –≤ IMG_DIR
HEADLESS = False                                  # False = –±—Ä–∞—É–∑–µ—Ä –≤–∏–¥–µ–Ω (–º–æ–∂–Ω–æ –ª–æ–≥–∏–Ω–∏—Ç—å—Å—è —Ä—É–∫–∞–º–∏)

# –û–ë–™–Å–ú –ò –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û–°–¢–¨
TEST_TOTAL = 766  # –ú–∞–∫—Å–∏–º—É–º –æ–±—ä—è–≤–ª–µ–Ω–∏–π –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—É—Å–∫ (–æ–±—Ä–µ–∂–µ—Ç—Å—è –ø–æ —Å–ø–∏—Å–∫—É —Å—Å—ã–ª–æ–∫)
CONCURRENCY = 3   # –°–∫–æ–ª—å–∫–æ –≤–∫–ª–∞–¥–æ–∫ (tab-–æ–≤) –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫—Ä—ã—Ç–æ (2‚Äì3 –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ)


# –ë–ê–ó–û–í–´–ï –¢–ê–ô–ú–ê–£–¢–´
CLICK_DELAY = 8       # –ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –æ–∂–∏–¥–∞–Ω–∏–µ–º –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å –Ω–æ–º–µ—Ä–æ–º
NAV_TIMEOUT = 90_000  # –¢–∞–π–º–∞—É—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –º—Å (90 —Å–µ–∫—É–Ω–¥)


# –ù–ê–°–¢–†–û–ô–ö–ò –ü–†–û–ö–°–ò
USE_PROXY = False                # True = –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–∫—Å–∏, False = –Ω–∞–ø—Ä—è–º—É—é
PROXY_HOST = "mproxy.site"       # –ê–¥—Ä–µ—Å –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–∞
PROXY_PORT = 17518               # –ü–æ—Ä—Ç –ø—Ä–æ–∫—Å–∏-—Å–µ—Ä–≤–µ—Ä–∞
PROXY_LOGIN = "YT4aBK"           # –õ–æ–≥–∏–Ω –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–æ–∫—Å–∏
PROXY_PASSWORD = "nUg2UTut9UMU"  # –ü–∞—Ä–æ–ª—å –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–æ–∫—Å–∏

# –ü–û–í–ï–î–ï–ù–ò–ï (–ú–ï–î–õ–ï–ù–ù–ï–ï –ò –ï–°–¢–ï–°–¢–í–ï–ù–ï–ï)
PAGE_DELAY_BETWEEN_BATCHES = (2.4, 5.2, )    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞—Ä—Ç–∏—è–º–∏ —Å—Å—ã–ª–æ–∫ (—Ä–∞–Ω—å—à–µ –±—ã–ª–∞ (2.0, 4.0))
NAV_STAGGER_BETWEEN_TABS = (0.45, 1.35, )    # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –æ—Ç–∫—Ä—ã—Ç–∏–µ–º –ö–ê–ñ–î–û–ô –≤–∫–ª–∞–¥–∫–∏ (—á—Ç–æ–±—ã –Ω–µ —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª–∏ –≤—Å–µ —Ä–∞–∑–æ–º)
POST_NAV_IDLE = (0.45, 1.05,)                # –ù–µ–±–æ–ª—å—à–∞—è ¬´–∑–∞–º–∏–Ω–∫–∞¬ª –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–µ—Ä–µ–¥ –¥–µ–π—Å—Ç–≤–∏—è–º–∏
BATCH_CONCURRENCY_JITTER = (True)            # –ò–Ω–æ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ–º 2 –≤–∫–ª–∞–¥–∫–∞–º–∏ –≤–º–µ—Å—Ç–æ 3 –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
CLOSE_STAGGER_BETWEEN_TABS = (0.25, 0.75, )  # –í–∫–ª–∞–¥–∫–∏ –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å –Ω–µ–±–æ–ª—å—à–æ–π —Å–ª—É—á–∞–π–Ω–æ–π –ø–∞—É–∑–æ–π


# USER-AGENT –±—Ä–∞—É–∑–µ—Ä–∞
UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/120.0.0.0 Safari/537.36"
)

# –ß–ï–õ–û–í–ï–ß–ù–û–°–¢–¨ / –ê–ù–¢–ò–ë–ê–ù-–ü–û–í–ï–î–ï–ù–ò–ï
HUMAN = {
    "pre_page_warmup_scrolls": (1, 3, ),      # –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ ¬´–ø—Ä–æ–≥—Ä–µ–ª–∏—Å—å¬ª —Å–∫—Ä–æ–ª–ª–æ–º –ø–æ—Å–ª–µ –æ—Ç–∫—Ä—ã—Ç–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    "scroll_step_px": (250, 900),             # –î–∏–∞–ø–∞–∑–æ–Ω —à–∞–≥–∞ —Å–∫—Ä–æ–ª–ª–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö
    "scroll_pause_s": (0.18, 0.75),           # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å–∫—Ä–æ–ª–ª–∞–º–∏
    "hover_pause_s": (0.14, 0.42),            # –ü–∞—É–∑–∞ –ø—Ä–∏ –Ω–∞–≤–µ–¥–µ–Ω–∏–∏ –Ω–∞ —ç–ª–µ–º–µ–Ω—Ç—ã
    "pre_click_pause_s": (0.10, 0.28),        # –ö–æ—Ä–æ—Ç–∫–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –∫–ª–∏–∫–æ–º
    "post_click_pause_s": (0.12, 0.32),       # –ü–∞—É–∑–∞ —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –∫–ª–∏–∫–∞
    "mouse_wiggle_px": (4, 12),               # –ê–º–ø–ª–∏—Ç—É–¥–∞ ¬´–ø–æ–¥—ë—Ä–≥–∏–≤–∞–Ω–∏—è¬ª –º—ã—à–∏
    "mouse_wiggle_steps": (2, 5),             # –°–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ —ç—Ç–∏—Ö ¬´–ø–æ–¥—ë—Ä–≥–∏–≤–∞–Ω–∏–π¬ª
    "between_actions_pause": (0.10, 0.30, ),  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –¥–µ–π—Å—Ç–≤–∏—è–º–∏ (—Å–∫—Ä–æ–ª–ª, –∫–ª–∏–∫, –Ω–∞–≤–µ–¥–µ–Ω–∏–µ)
    "click_delay_jitter": (
        CLICK_DELAY * 0.9,
        CLICK_DELAY * 1.25,
    ),  # –†–∞–∑–±—Ä–æ—Å –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ—Å–ª–µ –∫–ª–∏–∫–∞ –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É
    "randomize_selectors": True,  # –ò–Ω–æ–≥–¥–∞ –º–µ–Ω—è—Ç—å –ø–æ—Ä—è–¥–æ–∫ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤, —á—Ç–æ–±—ã –Ω–µ –±–∏—Ç—å –≤—Å–µ–≥–¥–∞ –≤ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ
}


# –¢–µ–≥–∏ –≤ phones_map.json –ø—Ä–∏ –ø—Ä–æ–ø—É—Å–∫–∞—Ö
TAG_NO_CALLS = "__SKIP_NO_CALLS__"        # –û–±—ä—è–≤–ª–µ–Ω–∏–µ ¬´–±–µ–∑ –∑–≤–æ–Ω–∫–æ–≤¬ª / —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è
TAG_UNAVAILABLE = "__SKIP_UNAVAILABLE__"  # –û–±—ä—è–≤–ª–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ/—É–¥–∞–ª–µ–Ω–æ/–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ
TAG_ON_REVIEW = "__SKIP_ON_REVIEW__"      # –û–±—ä—è–≤–ª–µ–Ω–∏–µ –µ—â—ë –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏
TAG_LIMIT = "__SKIP_LIMIT__"              # –ó–∞–∫–æ–Ω—á–∏–ª—Å—è –ª–∏–º–∏—Ç –ø–æ–∫–∞–∑–∞ –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –Ω–∞ –∞–∫–∫–∞—É–Ω—Ç–µ


# –•–ï–õ–ü–ï–†–´

def human_sleep(a: float, b: float):
    time.sleep(random.uniform(a, b))


def human_pause_jitter():
    human_sleep(*HUMAN["between_actions_pause"])


def human_scroll_jitter(page: Page, count: int | None = None):
    if count is None:
        count = random.randint(*HUMAN["pre_page_warmup_scrolls"])
    try:
        height = page.evaluate("() => document.body.scrollHeight") or 3000
        for _ in range(count):
            step = random.randint(*HUMAN["scroll_step_px"])
            direction = 1 if random.random() > 0.25 else -1
            y = max(0, min(height, page.evaluate("() => window.scrollY") + step * direction))
            page.evaluate("y => window.scrollTo({top: y, behavior: 'smooth'})", y)
            human_sleep(*HUMAN["scroll_pause_s"])
    except Exception:
        pass


def human_wiggle_mouse(page: Page, x: float, y: float):
    steps = random.randint(*HUMAN["mouse_wiggle_steps"])
    amp = random.randint(*HUMAN["mouse_wiggle_px"])
    for _ in range(steps):
        dx = random.randint(-amp, amp)
        dy = random.randint(-amp, amp)
        try:
            page.mouse.move(x + dx, y + dy)
        except Exception:
            pass
        human_pause_jitter()


def human_hover(page: Page, el):
    try:
        box = el.bounding_box()
        if not box:
            return
        cx = box["x"] + box["width"] * random.uniform(0.35, 0.65)
        cy = box["y"] + box["height"] * random.uniform(0.35, 0.65)
        page.mouse.move(cx, cy)
        human_wiggle_mouse(page, cx, cy)
        human_sleep(*HUMAN["hover_pause_s"])
    except Exception:
        pass


def safe_get_content(page: Page) -> str:
    for _ in range(2):
        try:
            return page.content()
        except PWError:
            time.sleep(1)
    return ""



def is_captcha_or_block(page: Page) -> bool:
    try:
        url = page.url.lower()
    except PWError:
        url = ""
    html = safe_get_content(page).lower()
    return (
        "captcha" in url or 
        "firewall" in url or
        "–¥–æ—Å—Ç—É–ø —Å –≤–∞—à–µ–≥–æ ip-–∞–¥—Ä–µ—Å–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω" in html
    )


def close_city_or_cookie_modals(page: Page):
    selectors = [
        "button[aria-label='–ó–∞–∫—Ä—ã—Ç—å']",
        "button[data-marker='modal-close']",
        "button[class*='close']",
        "button:has-text('–ü–æ–Ω—è—Ç–Ω–æ')",
        "button:has-text('–•–æ—Ä–æ—à–æ')",
        "button:has-text('–°–æ–≥–ª–∞—Å–µ–Ω')",
        "button:has-text('–ü—Ä–∏–Ω—è—Ç—å')",
    ]
    for b in page.query_selector_all(selectors):
        try:
            if b.is_visible():
                human_hover(page, b)
                b.click()
                human_sleep(0.25, 0.7)
        except Exception:
            continue


def close_login_modal_if_exists(page: Page) -> bool:
    """–ï—Å–ª–∏ –≤—ã–ª–µ–∑–ª–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ –∫–ª–∏–∫–∞ ‚Äî –∑–∞–∫—Ä—ã–≤–∞–µ–º –∏ —Å—á–∏—Ç–∞–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –Ω–µ—É–¥–∞—á–Ω—ã–º."""
    selectors_modal = [
        "[data-marker='login-form']",
        "[data-marker='registration-form']",
        "div[class*='modal'][class*='auth']",
        "div[class*='modal'] form[action*='login']",
    ]
    close_selectors = [
        "button[aria-label='–ó–∞–∫—Ä—ã—Ç—å']",
        "button[data-marker='modal-close']",
        "button[class*='close']",
        "button[type='button']",
    ]
    for sel in selectors_modal:
        try:
            modals = page.query_selector_all(sel)
        except PWError:
            continue
        for m in modals:
            if not m.is_visible():
                continue
            for btn_sel in close_selectors:
                btn = m.query_selector(btn_sel)
                if btn and btn.is_enabled():
                    try:
                        human_hover(page, btn)
                        human_sleep(*HUMAN["pre_click_pause_s"])
                        btn.click()
                        human_sleep(*HUMAN["post_click_pause_s"])
                        print("–ú–æ–¥–∞–ª–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–∫—Ä—ã—Ç–∞, –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ.")
                        return True
                    except Exception:
                        pass
            print("–ú–æ–¥–∞–ª–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–µ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç—Å—è ‚Äî –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            return True
    return False


def save_phone_png_from_data_uri(data_uri: str, file_stem: str) -> str | None:
    try:
        _, b64_data = data_uri.split(",", 1)
        raw = b64decode(b64_data)
        image = Image.open(BytesIO(raw)).convert("RGB")
        file_name = f"{file_stem}.png"
        out_path = IMG_DIR / file_name
        image.save(out_path)
        print(f"PNG —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {out_path}")
        return str(out_path)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ PNG: {e}")
        return None


def get_avito_id_from_url(url: str) -> str:
    m = re.search(r"(\d{7,})", url)
    return m.group(1) if m else str(int(time.time()))


def try_click(page: Page, el) -> bool:
    try:
        el.scroll_into_view_if_needed()
    except Exception:
        pass
    human_hover(page, el)
    human_sleep(*HUMAN["pre_click_pause_s"])
    try:
        el.click()
        human_sleep(*HUMAN["post_click_pause_s"])
        return True
    except Exception:
        try:
            box = el.bounding_box() or {}
            if box:
                page.mouse.move(box.get("x", 0) + 6, box.get("y", 0) + 6)
                human_sleep(*HUMAN["pre_click_pause_s"])
            page.evaluate("(e)=>e.click()", el)
            human_sleep(*HUMAN["post_click_pause_s"])
            return True
        except Exception:
            return False


# –ü–†–û–í–ï–†–ö–ê "–õ–ò–ú–ò–¢ –ö–û–ù–¢–ê–ö–¢–û–í"
def is_limit_contacts_modal(page: Page) -> bool:
    html = safe_get_content(page).lower()
    if "–∑–∞–∫–æ–Ω—á–∏–ª—Å—è –ª–∏–º–∏—Ç" in html and "–ø—Ä–æ—Å–º–æ—Ç—Ä –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤" in html:
        return True
    try:
        loc = page.locator("text=–ö—É–ø–∏—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç—ã").first
        if loc.is_visible():
            return True
    except Exception:
        pass
    return False


# –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –°–¢–†–ê–ù–ò–¶–´ –û–ë–™–Ø–í–õ–ï–ù–ò–Ø
NO_CALLS_MARKERS = [
    "–±–µ–∑ –∑–≤–æ–Ω–∫–æ–≤",
    "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è",
]
MODERATION_MARKERS = [
    "–æ–Ω–æ –µ—â—ë –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–µ",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–µ",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ –µ—â—ë –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–µ",
]
UNAVAILABLE_MARKERS = [
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ –Ω–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å–Ω—è—Ç–æ —Å –ø—Ä–æ–¥–∞–∂–∏",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ —É–¥–∞–ª–µ–Ω–æ",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–æ",
    "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ –±–æ–ª—å—à–µ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–æ",
]


def classify_ad_status(page: Page) -> str:
    """
    'ok' | 'no_calls' | 'on_review' | 'unavailable' | 'blocked' | 'limit'
    """
    if is_captcha_or_block(page):
        return "blocked"

    html = safe_get_content(page).lower()

    if is_limit_contacts_modal(page):
        return "limit"
    if any(m in html for m in MODERATION_MARKERS):
        return "on_review"
    if any(m in html for m in UNAVAILABLE_MARKERS):
        return "unavailable"
    if any(m in html for m in NO_CALLS_MARKERS):
        return "no_calls"

    try:
        if page.locator("text=–ë–µ–∑ –∑–≤–æ–Ω–∫–æ–≤").first.is_visible():
            return "no_calls"
    except Exception:
        pass

    return "ok"


# –í–•–û–î–ù–´–ï URL –ò–ó Excel/CSV

def read_urls_from_excel_or_csv(path: Path, sheet=None, url_column=None) -> list[str]:
    url_re = re.compile(r'https?://(?:www\.)?avito\.ru/[^\s"]+')
    urls: list[str] = []

    if path.suffix.lower() in {".xlsx", ".xls"}:
        xls = pd.ExcelFile(path)
        sheets = [sheet] if sheet is not None else xls.sheet_names
        for sh in sheets:
            df = xls.parse(sh, dtype=str)
            if url_column and url_column in df.columns:
                col = df[url_column].dropna().astype(str)
                urls.extend(col.tolist())
            else:
                for col in df.columns:
                    s = df[col].dropna().astype(str)
                    for val in s:
                        urls.extend(url_re.findall(val))
    elif path.suffix.lower() in {".csv", ".txt"}:
        df = pd.read_csv(path, dtype=str, sep=None, engine="python")
        if url_column and url_column in df.columns:
            col = df[url_column].dropna().astype(str)
            urls.extend(col.tolist())
        else:
            for col in df.columns:
                s = df[col].dropna().astype(str)
                for val in s:
                    urls.extend(url_re.findall(val))
    else:
        raise ValueError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è .xlsx/.xls/.csv/.txt")

    cleaned = []
    seen = set()
    for u in urls:
        u = u.strip()
        if not u.startswith("http"):
            u = urljoin("https://www.avito.ru", u)
        u = u.split("#", 1)[0]
        u = u.split("?", 1)[0]
        if u not in seen:
            seen.add(u)
            cleaned.append(u)
    return cleaned


# –ë–ï–ó–û–ü–ê–°–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï / –ß–¢–ï–ù–ò–ï –ü–†–û–ì–†–ï–°–°–ê

def atomic_write_json(path: Path, data):
    tmp = path.with_suffix(path.suffix + f".tmp_{int(time.time()*1000)}_{random.randint(1000,9999)}")
    payload = json.dumps(data, ensure_ascii=False, indent=2)
    tmp.write_text(payload, encoding="utf-8")
    attempts, delay = 10, 0.1
    for _ in range(attempts):
        try:
            os.replace(tmp, path)
            return
        except PermissionError:
            time.sleep(delay)
            delay = min(delay * 1.7, 1.0)
        except Exception:
            time.sleep(delay)
            delay = min(delay * 1.7, 1.0)
    try:
        path.write_text(payload, encoding="utf-8")
    except Exception as e:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")


def load_progress(path: Path) -> dict[str, str]:
    if path.exists():
        try:
            return json.loads(path.read_text(encoding="utf-8"))
        except Exception as e:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å: {e}")
    return {}


def load_pending(path: Path) -> list[str]:
    if path.exists():
        try:
            data = json.loads(path.read_text(encoding="utf-8"))
            return [u for u in data if isinstance(u, str)]
        except Exception:
            pass
    return []


def save_pending(path: Path, urls: list[str]):
    urls = list(dict.fromkeys(urls))  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ, –ø–æ—Ä—è–¥–æ–∫ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    atomic_write_json(path, urls)


def dump_debug(page: Page, url: str):
    try:
        ad_id = get_avito_id_from_url(url)
        png_path = DEBUG_DIR / f"{ad_id}.png"
        html_path = DEBUG_DIR / f"{ad_id}.html"
        page.screenshot(path=str(png_path), full_page=True)
        html = safe_get_content(page)
        html_path.write_text(html, encoding="utf-8")
        print(f"ü™™ Debug —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {png_path.name}, {html_path.name}")
    except Exception as e:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å debug: {e}")


# –õ–û–ì–ò–ö–ê –ö–õ–ò–ö–ê / –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø

def click_show_phone_on_ad(page: Page) -> bool:
    human_scroll_jitter(page)

    for anchor in [
        "[data-marker='seller-info']",
        "[data-marker='item-sidebar']",
        "section:has(button[data-marker*='phone'])",
        "section:has(button:has-text('–ü–æ–∫–∞–∑–∞—Ç—å'))",
    ]:
        try:
            a = page.query_selector(anchor)
            if a:
                a.scroll_into_view_if_needed()
                human_sleep(*HUMAN["scroll_pause_s"])
                break
        except Exception:
            pass

    selector_groups = [
        [
            "button[data-marker='item-phone-button']",
            "button[data-marker='phone-button/number']",
            "button[data-marker*='phone-button']",
        ],
        [
            "button:has-text('–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω')",
            "button:has-text('–ü–æ–∫–∞–∑–∞—Ç—å –Ω–æ–º–µ—Ä')",
            "a:has-text('–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω')",
            "a:has-text('–ü–æ–∫–∞–∑–∞—Ç—å –Ω–æ–º–µ—Ä')",
        ],
        [
            "button[aria-label*='–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω']",
            "button[aria-label*='–ü–æ–∫–∞–∑–∞—Ç—å –Ω–æ–º–µ—Ä']",
        ],
        [
            "[data-marker*='phone'] button",
            "[data-marker*='contacts'] button",
        ],
    ]

    if HUMAN["randomize_selectors"]:
        random.shuffle(selector_groups)
        for g in selector_groups:
            random.shuffle(g)

    try:
        page.wait_for_selector("button", timeout=2000)
    except Exception:
        pass

    for group in selector_groups:
        for sel in group:
            try:
                el = page.query_selector(sel)
                if el and el.is_visible() and el.is_enabled():
                    if try_click(page, el):
                        print("–ù–∞–∂–∞–ª–∏ '–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω'.")
                        return True
            except Exception:
                continue

    try:
        sticky = page.query_selector("footer:has(button)")
        if sticky:
            btn = sticky.query_selector("button")
            if btn and btn.is_visible() and btn.is_enabled():
                if try_click(page, btn):
                    print("–ù–∞–∂–∞–ª–∏ –∫–Ω–æ–ø–∫—É –≤ –ª–∏–ø–∫–æ–º —Ñ—É—Ç–µ—Ä–µ.")
                    return True
    except Exception:
        pass

    print("–ö–Ω–æ–ø–∫–∞ '–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    return False


def extract_phone_data_uri_on_ad(page: Page) -> str | None:
    try:
        img = page.query_selector("img[data-marker='phone-image']")
    except PWError:
        img = None

    if not img or not img.is_visible():
        print("–ö–∞—Ä—Ç–∏–Ω–∫–∞ —Å –Ω–æ–º–µ—Ä–æ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        return None

    # –ü–æ–ª—É—á–∞–µ–º src –∞—Ç—Ä–∏–±—É—Ç
    try:
        src = img.get_attribute("src") or ""
    except Exception:
        img = None
    if not src.startswith("data:image"):
        print(f"src –Ω–µ data:image, –∞: {src[:60]}...")
        return None
    return src


# –ü–£–õ –í–ö–õ–ê–î–û–ö (–¢–ê–ë–û–í) –ò –û–ë–†–ê–ë–û–¢–ö–ê –°–ü–ò–°–ö–û–í

def make_page_pool(context, size: int) -> list[Page]:
    return [context.new_page() for _ in range(size)]


def process_urls_with_pool(
    context, urls: list[str], on_result, pending_queue: list[str]
):
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ö–æ–¥: –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∫–ª–∞–¥–∫–∏ –∏ –∂–¥—ë–º DOMContentLoaded; –¥–æ–±–∞–≤–ª–µ–Ω—ã —Ä–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω—ã."""
    if not urls:
        return

    # –ü—É–ª —Å–æ–∑–¥–∞—ë–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞; —á–∞—Å—Ç—å –≤–∫–ª–∞–¥–æ–∫ –º–æ–∂–µ–º –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
    pages = make_page_pool(context, CONCURRENCY)
    try:
        it = iter(urls)
        while True:
            # –ò–Ω–æ–≥–¥–∞ –¥–µ–ª–∞–µ–º –ø–∞—Ä—Ç–∏—é –º–µ–Ω—å—à–µ –º–∞–∫—Å–∏–º—É–º–∞, —á—Ç–æ–±—ã –ø–æ–≤–µ–¥–µ–Ω–∏–µ –±—ã–ª–æ –º–µ–Ω–µ–µ —Ä–æ–≤–Ω—ã–º
            batch_size = (
                random.randint(max(1, CONCURRENCY - 1), CONCURRENCY)
                if BATCH_CONCURRENCY_JITTER
                else CONCURRENCY
            )
            batch_pages = pages[:batch_size]

            batch = []
            for idx, p in enumerate(batch_pages):
                try:
                    url = next(it)
                except StopIteration:
                    return
                batch.append((url, p))

                # –ù–µ –æ—Ç–∫—Ä—ã–≤–∞–µ–º –≤—Å–µ –≤–∫–ª–∞–¥–∫–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ ‚Äî —Å—Ç–∞–≤–∏–º –ø–∞—É–∑—É –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º goto
                human_sleep(*NAV_STAGGER_BETWEEN_TABS)
                try:
                    p.goto(url, wait_until="domcontentloaded", timeout=NAV_TIMEOUT)
                except PWTimeoutError:
                    print(f"–¢–∞–π–º–∞—É—Ç: {url}")
                    continue

                # –õ—ë–≥–∫–∞—è ¬´–∑–∞–º–∏–Ω–∫–∞¬ª –ø–æ—Å–ª–µ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ + –ø–∞—Ä–∞ —Å–∫—Ä–æ–ª–ª–æ–≤
                human_sleep(*POST_NAV_IDLE)
                human_scroll_jitter(p, count=random.randint(1, 2))

            # –°—Ç–∞—Ç—É—Å + –º–æ–¥–∞–ª–∫–∏ + –ø–æ–ø—ã—Ç–∫–∞ –∫–ª–∏–∫–∞ (—Ç–æ–∂–µ —á—É—Ç—å ¬´—Ä–∞–∑–º–∞–∑—ã–≤–∞–µ–º¬ª)
            for url, p in batch:
                human_pause_jitter()
                st = classify_ad_status(p)
                if st == "blocked":
                    print(f"–ö–∞–ø—á–∞/–±–ª–æ–∫: {url}")
                    continue
                if st == "on_review":
                    print(f"–ù–∞ –ø—Ä–æ–≤–µ—Ä–∫–µ: {url}")
                    on_result(url, TAG_ON_REVIEW)
                    pending_queue.append(url)
                    continue
                if st == "limit":
                    print(f"–õ–∏–º–∏—Ç –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤: {url}")
                    on_result(url, TAG_LIMIT)
                    pending_queue.append(url)
                    continue
                if st == "unavailable":
                    print(f"–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ/–∑–∞–∫—Ä—ã—Ç–æ: {url}")
                    on_result(url, TAG_UNAVAILABLE)
                    continue
                if st == "no_calls":
                    print(f"–ë–µ–∑ –∑–≤–æ–Ω–∫–æ–≤: {url}")
                    on_result(url, TAG_NO_CALLS)
                    continue

                close_city_or_cookie_modals(p)
                if not click_show_phone_on_ad(p):
                    # –ü—Ä–æ–≤–µ—Ä–∏–º –µ—â—ë —Ä–∞–∑ ‚Äî –≤–¥—Ä—É–≥ —ç—Ç–æ –≤—Å—ë –∂–µ on_review/limit/–∏ —Ç.–¥.
                    st2 = classify_ad_status(p)
                    if st2 == "on_review":
                        on_result(url, TAG_ON_REVIEW)
                        pending_queue.append(url)
                    elif st2 == "limit":
                        on_result(url, TAG_LIMIT)
                        pending_queue.append(url)
                    elif st2 == "unavailable":
                        on_result(url, TAG_UNAVAILABLE)
                    elif st2 == "no_calls":
                        on_result(url, TAG_NO_CALLS)
                    else:
                        dump_debug(p, url)

            # –ñ–¥—ë–º –∫–∞—Ä—Ç–∏–Ω–∫—É —Ç–µ–ª–µ—Ñ–æ–Ω–∞ (—Å –Ω–µ–±–æ–ª—å—à–∏–º –¥–∂–∏—Ç—Ç–µ—Ä–æ–º –º–µ–∂–¥—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏)
            human_sleep(*HUMAN["click_delay_jitter"])
            for url, p in batch:
                human_pause_jitter()
                if close_login_modal_if_exists(p) or is_captcha_or_block(p):
                    continue
                data_uri = extract_phone_data_uri_on_ad(p)
                if not data_uri:
                    continue
                if SAVE_DATA_URI:
                    value = data_uri
                else:
                    avito_id = get_avito_id_from_url(url)
                    out_path = save_phone_png_from_data_uri(data_uri, avito_id)
                    if not out_path:
                        continue
                    value = out_path
                on_result(url, value)
                print(f"{url} -> {'[data:image...]' if SAVE_DATA_URI else value}")

            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞—Ä—Ç–∏—è–º–∏ ‚Äî —Ç–æ–∂–µ —á—É—Ç—å —à–∏—Ä–µ
            human_sleep(*PAGE_DELAY_BETWEEN_BATCHES)
    finally:
        for p in pages:
            try:
                human_sleep(*CLOSE_STAGGER_BETWEEN_TABS)
                p.close()
            except Exception:
                pass


# –ü–ï–†–ï–ü–†–û–í–ï–†–ö–ê –û–ß–ï–†–ï–î–ò PENDING (–ö–û–†–û–¢–ö–ò–ô –ü–†–û–•–û–î)

def recheck_pending_once(context, on_result):
    pend = load_pending(PENDING_JSON)
    if not pend:
        return
    print(f"\n–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫: {len(pend)}")
    page = context.new_page()
    still = []
    for url in pend:
        try:
            human_sleep(*NAV_STAGGER_BETWEEN_TABS)  # –¢–æ–∂–µ –Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–µ–º ¬´–≤ –Ω–æ–ª—å¬ª
            page.goto(url, wait_until="domcontentloaded", timeout=NAV_TIMEOUT)
        except Exception:
            still.append(url)
            continue
        st = classify_ad_status(page)
        if st in ("on_review", "limit"):
            still.append(url)  # –ü–æ–∫–∞ —Ä–∞–Ω–æ
        elif st == "no_calls":
            on_result(url, TAG_NO_CALLS)
        elif st == "unavailable" or st == "blocked":
            on_result(url, TAG_UNAVAILABLE)
        else:
            # ok: –ø—Ä–æ–±—É–µ–º –∫–ª–∏–∫–Ω—É—Ç—å / —Å—á–∏—Ç–∞—Ç—å
            close_city_or_cookie_modals(page)
            if click_show_phone_on_ad(page):
                time.sleep(random.uniform(*HUMAN["click_delay_jitter"]))
                data_uri = extract_phone_data_uri_on_ad(page)
                if data_uri:
                    if SAVE_DATA_URI:
                        on_result(url, data_uri)
                    else:
                        out = save_phone_png_from_data_uri(data_uri, get_avito_id_from_url(url))
                        if out:
                            on_result(url, out)
                    print(f"(–ø–æ–≤—Ç–æ—Ä) {url}")
                else:
                    still.append(url)
            else:
                # –ï—Å–ª–∏ —Å–µ–π—á–∞—Å —Å—Ç–∞–ª–æ ¬´–±–µ–∑ –∑–≤–æ–Ω–∫–æ–≤/–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ¬ª
                st2 = classify_ad_status(page)
                if st2 == "no_calls":
                    on_result(url, TAG_NO_CALLS)
                elif st2 in ("on_review", "limit"):
                    still.append(url)
                else:
                    on_result(url, TAG_UNAVAILABLE)
        human_sleep(0.8, 1.6)
    try:
        page.close()
    except Exception:
        pass
    save_pending(PENDING_JSON, still)
    print(f"–û—Å—Ç–∞–ª–æ—Å—å –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö: {len(still)}")


# –û–°–ù–û–í–ù–û–ô –°–¶–ï–ù–ê–†–ò–ô

def main():
    urls = read_urls_from_excel_or_csv(INPUT_FILE, INPUT_SHEET, URL_COLUMN)
    urls = urls[:TEST_TOTAL]

    phones_map: dict[str, str] = load_progress(OUT_JSON)
    already_done = set(phones_map.keys())
    urls = [u for u in urls if u not in already_done]

    # –ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ ‚Äî —Å–Ω–∞—á–∞–ª–∞ –æ—á–µ—Ä–µ–¥—å pending
    pending_queue = load_pending(PENDING_JSON)

    print(f"–ù–æ–≤—ã—Ö —Å—Å—ã–ª–æ–∫ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(urls)}; –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö: {len(pending_queue)}")
    if not urls and not pending_queue:
        print(f"–ù–µ—á–µ–≥–æ –¥–µ–ª–∞—Ç—å. –ü—Ä–æ–≥—Ä–µ—Å—Å –≤ {OUT_JSON}: {len(phones_map)} –∑–∞–ø–∏—Å–µ–π.")
        return

    def flush_progress():
        try:
            atomic_write_json(OUT_JSON, phones_map)
            save_pending(PENDING_JSON, pending_queue)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")

    atexit.register(flush_progress)
    for sig in ("SIGINT", "SIGTERM"):
        try:
            signal.signal(getattr(signal, sig), lambda *a: (flush_progress(), exit(1)))
        except Exception:
            pass

    with sync_playwright() as p:
        launch_kwargs = {
            "headless": HEADLESS,
            "args": [
                "--disable-blink-features=AutomationControlled",
                "--start-maximized",
            ],
        }
        if USE_PROXY:
            launch_kwargs["proxy"] = {
                "server": f"http://{PROXY_HOST}:{PROXY_PORT}",
                "username": PROXY_LOGIN,
                "password": PROXY_PASSWORD,
            }

        browser = p.chromium.launch(**launch_kwargs)

        vp_w = random.randint(1200, 1368)
        vp_h = random.randint(760, 900)

        context = browser.new_context(
            viewport={"width": vp_w, "height": vp_h},
            user_agent=UA,
        )
        context.set_default_navigation_timeout(NAV_TIMEOUT)
        context.set_default_timeout(NAV_TIMEOUT)

        # –†—É—á–Ω–æ–π –ª–æ–≥–∏–Ω –Ω–∞ –ø–µ—Ä–≤–æ–π —Å—Å—ã–ª–∫–µ (–µ—Å–ª–∏ –µ—Å—Ç—å —á—Ç–æ –æ—Ç–∫—Ä—ã–≤–∞—Ç—å)
        seed_url = pending_queue[0] if pending_queue else (urls[0] if urls else None)
        if seed_url:
            page = context.new_page()
            try:
                page.goto(seed_url, wait_until="domcontentloaded", timeout=NAV_TIMEOUT)
            except PWTimeoutError:
                pass
            print("\n–¢–≤–æ–∏ –¥–µ–π—Å—Ç–≤–∏—è:")
            print(" ‚Ä¢ –µ—Å–ª–∏ –µ—Å—Ç—å –∫–∞–ø—á–∞ ‚Äî —Ä–µ—à–∏;")
            print(" ‚Ä¢ –∑–∞–ª–æ–≥–∏–Ω—å—Å—è –≤ –ê–≤–∏—Ç–æ;")
            print(" ‚Ä¢ –æ—Å—Ç–∞–≤—å –æ—Ç–∫—Ä—ã—Ç—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è.")
            input("–ì–æ—Ç–æ–≤? –ù–∞–∂–º–∏ Enter –≤ –∫–æ–Ω—Å–æ–ª–∏.\n")
            if is_captcha_or_block(page):
                print("–í—Å—ë –µ—â—ë –∫–∞–ø—á–∞/–±–ª–æ–∫ ‚Äî –≤—ã—Ö–æ–¥–∏–º.")
                browser.close()
                flush_progress()
                return
            try:
                page.close()
            except Exception:
                pass

        def on_result(url: str, value: str | None):
            # value: data:image..., –ø—É—Ç—å –∫ PNG –∏–ª–∏ __SKIP_*__
            if value is None:
                return
            phones_map[url] = value
            atomic_write_json(OUT_JSON, phones_map)

        # 1) –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º pending (—Å–Ω—è–≤ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ)
        pending_queue = [u for u in pending_queue if u not in already_done]
        try:
            process_urls_with_pool(
                context, pending_queue, on_result, pending_queue
            )  # –ù–æ–≤—ã–µ ¬´pending¬ª –¥–æ–±–∞–≤—è—Ç—Å—è –≤ –∫–æ–Ω–µ—Ü
        except KeyboardInterrupt:
            print("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (–Ω–∞ pending).")
            flush_progress()

        # 2) –ö–æ—Ä–æ—Ç–∫–∞—è –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–≥–æ, —á—Ç–æ –µ—â—ë –æ—Å—Ç–∞–ª–æ—Å—å –≤ pending –ø–æ—Å–ª–µ —à–∞–≥–∞ 1
        recheck_pending_once(context, on_result)

        # 3) –¢–µ–ø–µ—Ä—å –æ—Å–Ω–æ–≤–Ω–æ–π —Å–ø–∏—Å–æ–∫ –∏–∑ Excel
        try:
            process_urls_with_pool(context, urls, on_result, pending_queue)
        except KeyboardInterrupt:
            print("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (–Ω–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Å—ã–ª–∫–∞—Ö).")
            flush_progress()

        browser.close()
        flush_progress()
        print(
            f"\n–ì–æ—Ç–æ–≤–æ. –í {OUT_JSON} —Å–µ–π—á–∞—Å {len(phones_map)} –∑–∞–ø–∏—Å–µ–π. "
            f"–û—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö –æ—Å—Ç–∞–ª–æ—Å—å: {len(load_pending(PENDING_JSON))}"
        )


if __name__ == "__main__":
    main()
